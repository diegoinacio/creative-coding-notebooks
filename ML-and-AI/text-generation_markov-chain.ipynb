{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation [Markov Chain]\n",
    "---\n",
    "- Author: Diego Inácio\n",
    "- GitHub: [github.com/diegoinacio](https://github.com/diegoinacio)\n",
    "- Notebook: [text-generation_markov-chain.ipynb](https://github.com/diegoinacio/creative-coding-notebooks/blob/master/ML-and-AI/text-generation_markov-chain.ipynb)\n",
    "---\n",
    "Text generation with [*Markov Chain*](https://en.wikipedia.org/wiki/Markov_chain), using characters as base.\n",
    "\n",
    "A *Markov chain* is a sequence $x_1, x_2, x_3, ..., x_n$ of random variables - in our case, random characters. The distribution of the conditional probabilities of $x_{n+1}$ is a function of $x_n$, where:\n",
    "\n",
    "$$ \\large \\displaystyle \n",
    "\\Pr(X_{n+1}=x|X_{0},X_{1},X_{2},\\ldots ,X_{n})=\\Pr(X_{n+1}=x|X_{n})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "---\n",
    "As data, we are going to use lyrics from one of my favorite hard rock band.. **Van Halen**. To get those lyrics, let's scrape this data in the website [AllTheLyrics](https://www.allthelyrics.com) and process them to build a text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request and parse\n",
    "PAGE = \"https://www.allthelyrics.com\"\n",
    "URL = f'{PAGE}/lyrics/van_halen'\n",
    "request = requests.get(URL).text\n",
    "parse = BeautifulSoup(request, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00 %\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(1)\n",
    "# Define how many lyrics will be considered\n",
    "# p = 0.1 indicates that 10% will be read\n",
    "p = 0.2        # ! Parameter\n",
    "\n",
    "# Init text corpus\n",
    "TEXT = \"\"\n",
    "\n",
    "# Find all \n",
    "ITEM = parse.find_all(\"li\", {\"class\": \"lyrics-list-item\"})\n",
    "ITEM_alpha = np.random.choice([0, 1], len(ITEM), p=[1 - p, p])\n",
    "\n",
    "for i, item in enumerate(ITEM):\n",
    "    link = item.find(\"a\")\n",
    "    if not link or not ITEM_alpha[i]:\n",
    "        continue\n",
    "    url = f'{PAGE}{link[\"href\"]}'\n",
    "    request_ = requests.get(url).text\n",
    "    parse_ = BeautifulSoup(request_, \"html.parser\")\n",
    "    TEXT += parse_.find(\"div\", {\"class\": \"content-text-inner\"}).text\n",
    "    print(f'{100*i/len(ITEM):>06.02f} %', end=\"\\r\")\n",
    "TEXT = TEXT.replace(\"\\n\", \" \")\n",
    "print(f'{100:>06.02f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', \"'\", '(', ')', ',', '-', '.', '0', '1', '3', '5', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'º']\n"
     ]
    }
   ],
   "source": [
    "# Find all characters and symbols in the text\n",
    "SYMBOLS = sorted(set(TEXT))\n",
    "SYMBOLS_N = len(SYMBOLS)\n",
    "print(SYMBOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Matrix\n",
    "---\n",
    "[Transition](https://en.wikipedia.org/wiki/Markov_chain#Transitions) matrix contains all probilities for the next event, considering the current one. For example, considering the possibilities **A**, **B** and **C**:\n",
    "\n",
    "|     |  A   |  B   |  C  |\n",
    "| :-: | :--: | :--: | :-: |\n",
    "|  A  | 0.1  | 0.6  | 0.3 |\n",
    "|  B  | 0.25 | 0.05 | 0.7 |\n",
    "|  C  | 0.7  | 0.3  |  0  |\n",
    "\n",
    "If the current state is **A**, the probability of getting **B** is *0.6*.\n",
    "\n",
    "In this case, the transition matrix has order 1. For nth-order matrices, we consider the last **n** states in sequence. For example, a 2nd-order matrix would be:\n",
    "\n",
    "|     |  A   |  B   |  C  |\n",
    "| :-: | :--: | :--: | :-: |\n",
    "| AA  | 0.1  | 0.6  | 0.3 |\n",
    "| AB  | 0.25 | 0.05 | 0.7 |\n",
    "|  :  | ...  | ...  | ... |\n",
    "| CA  | 0.7  | 0.3  |  0  |\n",
    "|  :  | ...  | ...  | ... |\n",
    "\n",
    "The higher the order, the more \"readable\" the generated text will be.\n",
    "\n",
    "To build our transion matrix we have basically to calculate the probability of the states, depending on the order we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_sequences(TEXT, order):\n",
    "    \"\"\"\n",
    "    Return all character sequences with length equal to the order\n",
    "    \"\"\"\n",
    "    TEXT_N = len(TEXT)\n",
    "    ORDERS = [TEXT[i:i + order] for i in range(TEXT_N - order)]\n",
    "    return sorted(set(ORDERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(TEXT, ORDERS, order):\n",
    "    \"\"\"\n",
    "    Build transition matrix\n",
    "    \"\"\"\n",
    "    ORDERS_N = len(ORDERS)\n",
    "    P = np.ones([ORDERS_N, SYMBOLS_N])*1e-8\n",
    "    for i, e1 in enumerate(TEXT[order:], order):\n",
    "        i1 = SYMBOLS.index(e1)\n",
    "        e2 = TEXT[i-order:i]\n",
    "        i2 = ORDERS.index(e2)\n",
    "        P[i2, i1] += 1\n",
    "    P = P/P.sum(axis=1)[:,np.newaxis]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "---\n",
    "Having the transition matrix, we can start building the text generation procedure. The first step is to define the inital state and ganerate the following states by using the probabilities and choosing randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation(TEXT, order, lines):\n",
    "    \"\"\"\n",
    "    Generate text\n",
    "    \"\"\"\n",
    "    # Get transition matrix\n",
    "    ORDERS = order_sequences(TEXT, order)\n",
    "    P = transition_matrix(TEXT, ORDERS, order)\n",
    "    # Count the occurences in the text, for each sequence\n",
    "    # and define its probabilities\n",
    "    ORDERS_count = np.array([TEXT.count(o) for o in ORDERS])\n",
    "    ORDERS_p = ORDERS_count/ORDERS_count.sum()\n",
    "    # Build text\n",
    "    LINE = []\n",
    "    for _ in range(lines):\n",
    "        # Define initial chain of characters randomly\n",
    "        line = np.random.choice(ORDERS, 1, p=ORDERS_p)[0]\n",
    "        symbol = line[-1]\n",
    "        line_s = np.random.randint(20, 50)\n",
    "        while (len(line) < line_s) or (symbol not in [\" \", \",\", \".\", \"!\"]):\n",
    "            p = P[0]*0 + 1\n",
    "            index0 = ORDERS.index(line[-order:])\n",
    "            p *= P[index0]\n",
    "            index1 = np.random.choice(SYMBOLS_N, 1, p=p/p.sum())[0]\n",
    "            symbol = SYMBOLS[index1]\n",
    "            line += symbol\n",
    "        LINE += [line]\n",
    "    return \"\\n\".join(LINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "---\n",
    "In order to visualize the impact of the order in the transition matrix, let's generate texts with multiple nth-order matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st-order Matrix\n",
    "---\n",
    "In this case, we just consider the current character probabilities, which is likely to produce a weird text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et y gelwn'scanseayour lous Heemag,\n",
      " t swilo) wal 10 be m me he, llivet St. wassthin'tayot \n",
      "veveroniee rere th is ike Gofa.\n",
      "horer chth t t, sh! Pa. sh Ith, s myolinof I'shaye'stha \n",
      "d I f Totot sep paront (rad it's \n",
      "d k wn am t'vestsedomee mat wh, n het y'verehangouronghanallive \n",
      "e Bure choh Do Ifisol co oheterodan're \n",
      " buin' lieede s lo drorowno) rer \n",
      "\n",
      "p d oune ived,iguppathet \n",
      "our iny bere k t Anongheve reve I Nouronooun I \n",
      " maywatyel yowh sot ckndicitheromyelitroun'veas \n",
      "unt st lerende (d lsainttow,\n",
      " f t y h, in' St mu if sis \n",
      " fu youngh fend, (ray \n",
      "bakn ) t'mowevere t \n",
      "buplilirdr s sat'.. st ag g Oou betin'tawhe \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(text_generation(TEXT, 1, 8), end=\"\\n\\n\")\n",
    "print(text_generation(TEXT, 1, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd-order Matrix\n",
    "---\n",
    "In this case, we consider the last 3 characters probabilities, which is likely to produce a more comprehensive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e... what you know mine, lovin' \n",
      "led, round, round, near all \n",
      " stillin', I'd, round, round, \n",
      "ound, For divide it ride your belin' Go some down \n",
      "ring in me world Give You Oucheeliever Uh,\n",
      ", Are mone body sharely Only to how who \n",
      " ooo) what you wake it wer be the \n",
      " be subtle with someone can puts \n",
      "\n",
      "ed a wheek a 3 piece ream,\n",
      " give else what want life You'll me everywhen the \n",
      "pail Sweet it hey you want \n",
      "ook in ove and neve it nothing you know show magic,\n",
      " must turn you Dig deny \n",
      "on! Dream, get she's comind want little We're \n",
      "ed upon the comind the a stop lost of want faithough \n",
      "m feeliever a litter (Ooooh oooh \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(text_generation(TEXT, 3, 8), end=\"\\n\\n\")\n",
    "print(text_generation(TEXT, 3, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7th-order Matrix\n",
    "---\n",
    "In this case, we consider the last 7 characters probabilities, which is likely to produce a little more comprehensive sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e. Standing on top of the women \n",
      "see baby now! Hey, you don't always been \n",
      "o live Give to live Give \n",
      "n'....no, don't know, Cause it's gonna stop \n",
      " Love hurts you sometimes \n",
      "ed up in lights Everything you've got to give You've \n",
      "st once born, can't ever lose faith \n",
      " I wonder who I'd rather be if I had one wish \n",
      "\n",
      "o try, oh could it ever \n",
      "ce can't refuse I wouldn't know and \n",
      "st believe a little If you want faith, you just \n",
      "or is a little while your head,\n",
      "round) Run-run-runaround, round) \n",
      "ever had no room to second guess puts me under \n",
      "thing's gonna like it Hey! Alright! Whoo! How 'bout \n",
      "ed Oh, what a fool believe You can always make \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(text_generation(TEXT, 7, 8), end=\"\\n\\n\")\n",
    "print(text_generation(TEXT, 7, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
