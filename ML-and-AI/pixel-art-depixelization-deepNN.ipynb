{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depixelizing Pixel Art using Deep Neural Networks\n",
    "---\n",
    "- Author: Diego In√°cio\n",
    "- GitHub: [github.com/diegoinacio](https://github.com/diegoinacio)\n",
    "- Notebook: [pixel-art-depixelization-deepNN.ipynb](https://github.com/diegoinacio/creative-coding-notebooks/blob/master/ML-and-AI/pixel-art-depixelization-deepNN.ipynb)\n",
    "---\n",
    "A pretty naive approach that *upscales* and *depixelizes* a very low-res pixel art using deep *Neural Network*.\n",
    "\n",
    "The main idea is given the 2D coordinate inputs, get the relative pixel color as the output. To avoid the color interpolation and *blurry* results, store the original color pallete and transpose it using the concept of *one-hot* encodation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "---\n",
    "Read a very low-res pixel art image (preferably 8bits to avoid a very large color pallete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read input image ###\n",
    "img_in = Image.open('../_data/pixel-art-mario.png')\n",
    "img_in = np.asarray(img_in)/255\n",
    "n1, n2, c = img_in.shape\n",
    "\n",
    "### Split channels ###\n",
    "R, G, B = img_in[:,:,0], img_in[:,:,1], img_in[:,:,2]\n",
    "\n",
    "### Get color pallete ###\n",
    "color_pallete = np.unique(\n",
    "    np.array([R.ravel(), G.ravel(), B.ravel()]).T,\n",
    "    axis=0\n",
    ")\n",
    "color_pallete = color_pallete[color_pallete.sum(axis=1).argsort()]\n",
    "\n",
    "### Coordiantes ###\n",
    "T, S = np.mgrid[0:n1, 0:n2]\n",
    "# Standardize coordinates\n",
    "S = (S - S.mean())/S.std()\n",
    "T = (T - T.mean())/T.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "fig, [axA, axB] = plt.subplots(1, 2)\n",
    "\n",
    "ST = np.stack([S, T, S*0], axis=2)\n",
    "ST = (ST - ST.min())/(ST.max() - ST.min())\n",
    "ST[:,:,2] = 0\n",
    "axA.imshow(ST); axA.axis('off')\n",
    "axA.set_title('X Train')\n",
    "axA.text(1, 3, f'({S.min():.3f}, {T.min():.3f})', color='w', size=20)\n",
    "axA.text(21, 3, f'({S.max():.3f}, {T.min():.3f})', color='w', size=20)\n",
    "axA.text(1, 29, f'({S.min():.3f}, {T.max():.3f})', color='w', size=20)\n",
    "axA.text(21, 29, f'({S.max():.3f}, {T.max():.3f})', color='w', size=20)\n",
    "\n",
    "axB.imshow(img_in)\n",
    "axB.set_title('Input image')\n",
    "\n",
    "# Color pallete\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.imshow(color_pallete[:, np.newaxis, :].reshape((1, -1, 3)))\n",
    "ax.set_title('Color Pallete'); ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "X_train = np.array([S.ravel(), T.ravel()]).T\n",
    "\n",
    "Y_train = np.array([R.ravel(), G.ravel(), B.ravel()]).T\n",
    "Y_train_pallete = np.unique(Y_train, axis=0)\n",
    "Y_train_pallete = Y_train_pallete[Y_train_pallete.sum(axis=1).argsort()]\n",
    "# One-hot encoding based on the color pallete\n",
    "Y_train_oh = np.zeros((Y_train.shape[0], Y_train_pallete.shape[0]))\n",
    "n, m = Y_train_oh.shape\n",
    "for i in range(Y_train_oh.shape[0]):\n",
    "    for j in range(Y_train_oh.shape[1]):\n",
    "        Y_train_oh[i, j] = 1 if np.array_equal(Y_train[i], Y_train_pallete[j]) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "N1 = N2 = 640\n",
    "t, s = np.mgrid[0:N1, 0:N2]\n",
    "s = (s - s.mean())/s.std()\n",
    "t = (t - t.mean())/t.std()\n",
    "X_test = np.array([s.ravel(), t.ravel()], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network\n",
    "---\n",
    "The archtecture of the *NeuralNet* is inspired by the concept of a *decoder* of an *autoencoder*. The output is an *one-hot* encoding of the *color pallete*, which is activated by a *softmax* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid error: \"InternalError:  Blas GEMM launch failed...\" (RTX card)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define NN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.125),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.125),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(m, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "epochs = 100\n",
    "for i in range(10):\n",
    "    print(f'\\nepochs: {i*epochs:04d} - {(i + 1)*epochs:04d}')\n",
    "    model.fit(\n",
    "        X_train, Y_train_oh,\n",
    "        epochs=epochs - 1,\n",
    "        verbose=0\n",
    "    )\n",
    "    # Verbose\n",
    "    model.fit(\n",
    "        X_train, Y_train_oh,\n",
    "        epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axA, axB] = plt.subplots(1, 2)\n",
    "\n",
    "axA.imshow(img_in)\n",
    "axA.set_title(f'$Y_{{train}}$ ({n1} x {n2})', size=20)\n",
    "# Predict using X_train (32x32x3)\n",
    "Y_predA = model.predict(X_train)\n",
    "Y_predA = np.vstack(\n",
    "    [Y_train_pallete[i] for i in np.argmax(Y_predA, axis=1)]\n",
    ")\n",
    "Y_predA = Y_predA.reshape(n1, n2, c)\n",
    "axB.imshow(Y_predA)\n",
    "axB.set_title(f'$\\hat{{Y}}_{{train}}$ ({n1} x {n2})', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axA = plt.subplots(1, 1, figsize=(20, 20))\n",
    "\n",
    "# Predict using X_test (512x512x3)\n",
    "Y_predB = model.predict(X_test)\n",
    "Y_predB = np.vstack(\n",
    "    [Y_train_pallete[i] for i in np.argmax(Y_predB, axis=1)]\n",
    ")\n",
    "Y_predB = Y_predB.reshape(N1, N2, c)\n",
    "axA.imshow(Y_predB)\n",
    "axA.set_title(f'$\\hat{{Y}}_{{test}}$ ({N1} x {N2})', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning process visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"https://www.youtube.com/embed/ROlbzTyWJDs\", width=\"960\", height=\"540\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
